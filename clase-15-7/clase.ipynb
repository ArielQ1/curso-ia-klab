{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8022be2e",
   "metadata": {},
   "source": [
    "## Grafica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f90a273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.  0.  5. ...  1.  0.  0.]\n",
      "  [ 0.  0. 13. ... 15.  5.  0.]\n",
      "  [ 0.  3. 15. ... 11.  8.  0.]\n",
      "  ...\n",
      "  [ 0.  4. 11. ... 12.  7.  0.]\n",
      "  [ 0.  2. 14. ... 12.  0.  0.]\n",
      "  [ 0.  0.  6. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  5.  0.  0.]\n",
      "  [ 0.  0.  0. ...  9.  0.  0.]\n",
      "  [ 0.  0.  3. ...  6.  0.  0.]\n",
      "  ...\n",
      "  [ 0.  0.  1. ...  6.  0.  0.]\n",
      "  [ 0.  0.  1. ...  6.  0.  0.]\n",
      "  [ 0.  0.  0. ... 10.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ... 12.  0.  0.]\n",
      "  [ 0.  0.  3. ... 14.  0.  0.]\n",
      "  [ 0.  0.  8. ... 16.  0.  0.]\n",
      "  ...\n",
      "  [ 0.  9. 16. ...  0.  0.  0.]\n",
      "  [ 0.  3. 13. ... 11.  5.  0.]\n",
      "  [ 0.  0.  0. ... 16.  9.  0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.  0.  1. ...  1.  0.  0.]\n",
      "  [ 0.  0. 13. ...  2.  1.  0.]\n",
      "  [ 0.  0. 16. ... 16.  5.  0.]\n",
      "  ...\n",
      "  [ 0.  0. 16. ... 15.  0.  0.]\n",
      "  [ 0.  0. 15. ... 16.  0.  0.]\n",
      "  [ 0.  0.  2. ...  6.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  2. ...  0.  0.  0.]\n",
      "  [ 0.  0. 14. ... 15.  1.  0.]\n",
      "  [ 0.  4. 16. ... 16.  7.  0.]\n",
      "  ...\n",
      "  [ 0.  0.  0. ... 16.  2.  0.]\n",
      "  [ 0.  0.  4. ... 16.  2.  0.]\n",
      "  [ 0.  0.  5. ... 12.  0.  0.]]\n",
      "\n",
      " [[ 0.  0. 10. ...  1.  0.  0.]\n",
      "  [ 0.  2. 16. ...  1.  0.  0.]\n",
      "  [ 0.  0. 15. ... 15.  0.  0.]\n",
      "  ...\n",
      "  [ 0.  4. 16. ... 16.  6.  0.]\n",
      "  [ 0.  8. 16. ... 16.  8.  0.]\n",
      "  [ 0.  1.  8. ... 12.  1.  0.]]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x100 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "digitos = load_digits()\n",
    "#x = digitos.data\n",
    "x = digitos.images\n",
    "y = digitos.target\n",
    "print(x)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "# se dibujara los diez primeros digitos\n",
    "plt.figure(figsize=(10, 1))\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(x[i], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9cafb01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.  0.  5. ...  1.  0.  0.]\n",
      "  [ 0.  0. 13. ... 15.  5.  0.]\n",
      "  [ 0.  3. 15. ... 11.  8.  0.]\n",
      "  ...\n",
      "  [ 0.  4. 11. ... 12.  7.  0.]\n",
      "  [ 0.  2. 14. ... 12.  0.  0.]\n",
      "  [ 0.  0.  6. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  5.  0.  0.]\n",
      "  [ 0.  0.  0. ...  9.  0.  0.]\n",
      "  [ 0.  0.  3. ...  6.  0.  0.]\n",
      "  ...\n",
      "  [ 0.  0.  1. ...  6.  0.  0.]\n",
      "  [ 0.  0.  1. ...  6.  0.  0.]\n",
      "  [ 0.  0.  0. ... 10.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ... 12.  0.  0.]\n",
      "  [ 0.  0.  3. ... 14.  0.  0.]\n",
      "  [ 0.  0.  8. ... 16.  0.  0.]\n",
      "  ...\n",
      "  [ 0.  9. 16. ...  0.  0.  0.]\n",
      "  [ 0.  3. 13. ... 11.  5.  0.]\n",
      "  [ 0.  0.  0. ... 16.  9.  0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.  0.  1. ...  1.  0.  0.]\n",
      "  [ 0.  0. 13. ...  2.  1.  0.]\n",
      "  [ 0.  0. 16. ... 16.  5.  0.]\n",
      "  ...\n",
      "  [ 0.  0. 16. ... 15.  0.  0.]\n",
      "  [ 0.  0. 15. ... 16.  0.  0.]\n",
      "  [ 0.  0.  2. ...  6.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  2. ...  0.  0.  0.]\n",
      "  [ 0.  0. 14. ... 15.  1.  0.]\n",
      "  [ 0.  4. 16. ... 16.  7.  0.]\n",
      "  ...\n",
      "  [ 0.  0.  0. ... 16.  2.  0.]\n",
      "  [ 0.  0.  4. ... 16.  2.  0.]\n",
      "  [ 0.  0.  5. ... 12.  0.  0.]]\n",
      "\n",
      " [[ 0.  0. 10. ...  1.  0.  0.]\n",
      "  [ 0.  2. 16. ...  1.  0.  0.]\n",
      "  [ 0.  0. 15. ... 15.  0.  0.]\n",
      "  ...\n",
      "  [ 0.  4. 16. ... 16.  6.  0.]\n",
      "  [ 0.  8. 16. ... 16.  8.  0.]\n",
      "  [ 0.  1.  8. ... 12.  1.  0.]]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x100 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 5 8 2 2 7 1 4 0 8 7 1 1 8 5 0 5 5 2 1 8 0 1 7 8 2 8 7 4 2 3 3 8 1 3 3 0\n",
      " 9 8 7 7 4 8 1 5 9 1 9 4 5 5 7 7 4 1 9 8 3 2 7 9 3 9 7 7 5 8 4 9 1 1 7 9 2\n",
      " 6 4 6 6 2 1 0 9 7 4 4 7 0 9 1 1 6 9 3 5 6 0 1 0 0 7 8 0 5 9 0 7 2 1 2 2 3\n",
      " 0 4 9 3 1 8 4 5 9 2 3 7 6 2 8 8 8 3 7 6 5 3 8 3 5 4 6 1 3 1 8 3 4 7 7 4 5\n",
      " 3 7 8 6 7 9 8 8 0 5 1 6 7 9 9 3 5 4 0 1 5 2 4 7 6 8 8 4 8 0 3 3 3 1 0 2 5\n",
      " 8 8 6 1 0 6 0 5 5 5 8 6 1 5 6 5 8 8 3 2 5 6 4 9 9 1 6 6 2 7 8 8 9 5 0 1 2\n",
      " 7 4 7 3 6 7 8 1 0 2 2 1 6 6 1 4 9 0 2 7 6 0 6 1 1 7 6 7 7 9 6 9 4 0 0 2 3\n",
      " 8 7 7 2 9 5 0 0 7 0 2 2 6 7 7 7 9 5 3 5 8 7 0 7 9 6 4 9 1 7 6 5 8 5 9 1 3\n",
      " 3 8 2 6 9 3 7 3 4 7 6 2 5 3 4 9 8 8 3 0 9 7 7 6 1 1 0 2 8 3 1 4 6 9 6 4 7\n",
      " 9 8 5 8 1 0 2 0 0 7 0 2 2 6 8 2 0 6 8 7 1 8 2 0 3 5 5]\n",
      "[5 5 8 2 2 7 1 4 0 8 7 1 1 8 5 0 5 5 2 1 8 0 1 7 8 2 3 7 4 2 3 3 8 1 3 3 0\n",
      " 9 8 7 7 4 8 8 3 9 1 9 4 5 5 7 7 4 1 9 8 3 2 7 9 3 9 7 7 5 8 4 9 1 1 7 9 2\n",
      " 6 4 6 6 2 1 0 9 7 4 4 7 0 9 1 1 6 9 3 5 6 0 1 0 0 7 8 0 5 9 0 7 2 1 2 2 3\n",
      " 0 4 9 3 1 8 4 5 9 2 3 7 6 2 8 8 8 3 7 6 5 3 1 3 5 4 6 1 3 1 8 3 4 7 7 4 5\n",
      " 3 7 8 6 7 9 8 8 0 5 1 6 7 9 9 3 5 4 0 1 5 2 4 7 6 8 8 4 8 0 3 3 3 1 0 2 5\n",
      " 8 8 6 1 0 6 0 5 5 5 8 6 1 3 0 5 8 8 3 2 5 6 4 9 9 1 6 6 2 7 8 8 9 3 0 1 2\n",
      " 7 4 7 3 6 7 8 1 0 2 2 1 6 6 1 4 9 0 2 7 6 6 6 1 8 7 6 7 7 9 6 9 4 0 0 2 3\n",
      " 7 7 7 2 9 5 0 0 7 0 2 2 6 7 7 7 9 5 3 5 8 7 0 7 9 6 4 9 1 7 6 5 8 5 9 1 3\n",
      " 3 8 2 6 9 3 7 3 4 7 6 2 5 3 4 9 8 8 3 0 9 7 7 6 1 1 0 2 8 3 1 4 6 9 6 4 2\n",
      " 9 8 5 8 1 0 2 0 0 7 6 2 2 6 3 2 0 6 8 7 1 8 2 0 3 5 5]\n",
      "0.9638888888888889\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy as np\n",
    "\n",
    "digitos = load_digits()\n",
    "#x = digitos.data\n",
    "x = digitos.images\n",
    "# esto responde a una arquitectura\n",
    "# x = x.reshape(len(x) - 1 )\n",
    "\n",
    "y = digitos.target\n",
    "print(x)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "# se dibujara los diez primeros digitos\n",
    "plt.figure(figsize=(10, 1))\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(x[i], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "clasificador = MLPClassifier(hidden_layer_sizes=(64, 32), activation=\"relu\")\n",
    "\n",
    "# reshape x_train and x_test to (samples, 64)\n",
    "x_train_reshaped = x_train.reshape((x_train.shape[0], -1))\n",
    "x_test_reshaped = x_test.reshape((x_test.shape[0], -1))\n",
    "\n",
    "clasificador.fit(x_train_reshaped, y_train)\n",
    "y_calculado = clasificador.predict(x_test_reshaped)\n",
    "\n",
    "print(y_calculado)\n",
    "print(y_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_calculado))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ee766c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (25.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (4.13.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.73.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.10.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting numpy<2.2.0,>=1.26.0 (from tensorflow)\n",
      "  Downloading numpy-2.1.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Downloading markdown-3.8.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow)\n",
      "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.16.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/codespace/.local/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/codespace/.local/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (645.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m645.0/645.0 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.73.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.1.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading h5py-3.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.10.0-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading markdown-3.8.2-py3-none-any.whl (106 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (89 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.16.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (412 kB)\n",
      "Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, werkzeug, termcolor, tensorboard-data-server, protobuf, optree, opt-einsum, numpy, mdurl, markdown, grpcio, google-pasta, gast, absl-py, tensorboard, ml-dtypes, markdown-it-py, h5py, astunparse, rich, keras, tensorflow\n",
      "\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/26\u001b[0m [wheel]ng]\u001b[33m  WARNING: The script wheel is installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K  Attempting uninstall: numpym╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/26\u001b[0m [optree]f]\n",
      "\u001b[2K    Found existing installation: numpy 2.2.6━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/26\u001b[0m [optree]\n",
      "\u001b[2K    Uninstalling numpy-2.2.6:[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/26\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled numpy-2.2.6━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/26\u001b[0m [numpy]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/26\u001b[0m [numpy]\u001b[33m  WARNING: The scripts f2py and numpy-config are installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/26\u001b[0m [markdown]\u001b[33m  WARNING: The script markdown_py is installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m18/26\u001b[0m [tensorboard]\u001b[33m  WARNING: The script tensorboard is installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m20/26\u001b[0m [markdown-it-py]\u001b[33m  WARNING: The script markdown-it is installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m25/26\u001b[0m [tensorflow]\u001b[33m  WARNING: The scripts import_pb_to_tensorboard, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert and toco are installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26/26\u001b[0m [tensorflow]6\u001b[0m [tensorflow]\n",
      "\u001b[1A\u001b[2KSuccessfully installed absl-py-2.3.1 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.73.1 h5py-3.14.0 keras-3.10.0 libclang-18.1.1 markdown-3.8.2 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.5.1 namex-0.1.0 numpy-2.1.3 opt-einsum-3.4.0 optree-0.16.0 protobuf-5.29.5 rich-14.0.0 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 termcolor-3.1.0 werkzeug-3.1.3 wheel-0.45.1 wrapt-1.17.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ef06be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-15 15:15:20.541146: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-15 15:15:20.817996: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-15 15:15:21.017674: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752592521.275023    8984 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752592521.361620    8984 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1752592521.933360    8984 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752592521.933388    8984 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752592521.933390    8984 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752592521.933392    8984 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-15 15:15:21.957800: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.19.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "331384e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.0779 - loss: 2.3682 - val_accuracy: 0.1771 - val_loss: 2.2022\n",
      "Epoch 2/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2228 - loss: 2.1125 - val_accuracy: 0.3021 - val_loss: 2.0360\n",
      "Epoch 3/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3612 - loss: 1.9429 - val_accuracy: 0.3264 - val_loss: 1.8815\n",
      "Epoch 4/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3571 - loss: 1.8057 - val_accuracy: 0.3576 - val_loss: 1.7319\n",
      "Epoch 5/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3978 - loss: 1.6686 - val_accuracy: 0.3924 - val_loss: 1.5925\n",
      "Epoch 6/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4497 - loss: 1.4880 - val_accuracy: 0.5035 - val_loss: 1.4451\n",
      "Epoch 7/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5254 - loss: 1.3648 - val_accuracy: 0.5729 - val_loss: 1.2898\n",
      "Epoch 8/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6090 - loss: 1.2200 - val_accuracy: 0.6528 - val_loss: 1.1252\n",
      "Epoch 9/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7200 - loss: 1.0564 - val_accuracy: 0.7188 - val_loss: 0.9512\n",
      "Epoch 10/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7947 - loss: 0.8693 - val_accuracy: 0.7674 - val_loss: 0.7932\n",
      "Epoch 11/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8545 - loss: 0.6668 - val_accuracy: 0.8090 - val_loss: 0.6758\n",
      "Epoch 12/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8497 - loss: 0.5701 - val_accuracy: 0.8264 - val_loss: 0.5853\n",
      "Epoch 13/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8906 - loss: 0.4778 - val_accuracy: 0.8299 - val_loss: 0.5221\n",
      "Epoch 14/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9199 - loss: 0.3857 - val_accuracy: 0.8403 - val_loss: 0.4735\n",
      "Epoch 15/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9255 - loss: 0.3512 - val_accuracy: 0.8472 - val_loss: 0.4332\n",
      "Epoch 16/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9375 - loss: 0.2921 - val_accuracy: 0.8542 - val_loss: 0.4038\n",
      "Epoch 17/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9367 - loss: 0.2924 - val_accuracy: 0.8646 - val_loss: 0.3782\n",
      "Epoch 18/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9494 - loss: 0.2273 - val_accuracy: 0.8681 - val_loss: 0.3592\n",
      "Epoch 19/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9430 - loss: 0.2394 - val_accuracy: 0.8854 - val_loss: 0.3398\n",
      "Epoch 20/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9472 - loss: 0.2152 - val_accuracy: 0.8889 - val_loss: 0.3277\n",
      "Epoch 21/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9555 - loss: 0.2153 - val_accuracy: 0.8924 - val_loss: 0.3131\n",
      "Epoch 22/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9610 - loss: 0.1837 - val_accuracy: 0.8958 - val_loss: 0.3030\n",
      "Epoch 23/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9607 - loss: 0.1831 - val_accuracy: 0.8993 - val_loss: 0.2923\n",
      "Epoch 24/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9677 - loss: 0.1628 - val_accuracy: 0.8958 - val_loss: 0.2872\n",
      "Epoch 25/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9605 - loss: 0.1594 - val_accuracy: 0.8958 - val_loss: 0.2786\n",
      "Epoch 26/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9650 - loss: 0.1418 - val_accuracy: 0.8993 - val_loss: 0.2715\n",
      "Epoch 27/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9770 - loss: 0.1242 - val_accuracy: 0.9062 - val_loss: 0.2662\n",
      "Epoch 28/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9686 - loss: 0.1294 - val_accuracy: 0.9097 - val_loss: 0.2634\n",
      "Epoch 29/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9730 - loss: 0.1210 - val_accuracy: 0.9132 - val_loss: 0.2589\n",
      "Epoch 30/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9751 - loss: 0.1143 - val_accuracy: 0.9132 - val_loss: 0.2564\n",
      "Epoch 31/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9719 - loss: 0.1105 - val_accuracy: 0.9097 - val_loss: 0.2541\n",
      "Epoch 32/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9811 - loss: 0.0940 - val_accuracy: 0.9132 - val_loss: 0.2520\n",
      "Epoch 33/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9814 - loss: 0.0969 - val_accuracy: 0.9132 - val_loss: 0.2501\n",
      "Epoch 34/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9778 - loss: 0.0970 - val_accuracy: 0.9132 - val_loss: 0.2476\n",
      "Epoch 35/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9838 - loss: 0.0890 - val_accuracy: 0.9132 - val_loss: 0.2456\n",
      "Epoch 36/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9841 - loss: 0.0780 - val_accuracy: 0.9132 - val_loss: 0.2451\n",
      "Epoch 37/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9777 - loss: 0.0993 - val_accuracy: 0.9201 - val_loss: 0.2444\n",
      "Epoch 38/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9856 - loss: 0.0778 - val_accuracy: 0.9167 - val_loss: 0.2433\n",
      "Epoch 39/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9799 - loss: 0.0882 - val_accuracy: 0.9236 - val_loss: 0.2426\n",
      "Epoch 40/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9805 - loss: 0.0807 - val_accuracy: 0.9201 - val_loss: 0.2405\n",
      "Epoch 41/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9877 - loss: 0.0654 - val_accuracy: 0.9201 - val_loss: 0.2443\n",
      "Epoch 42/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9852 - loss: 0.0704 - val_accuracy: 0.9236 - val_loss: 0.2425\n",
      "Epoch 43/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9838 - loss: 0.0673 - val_accuracy: 0.9236 - val_loss: 0.2431\n",
      "Epoch 44/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9884 - loss: 0.0592 - val_accuracy: 0.9271 - val_loss: 0.2396\n",
      "Epoch 45/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9868 - loss: 0.0606 - val_accuracy: 0.9306 - val_loss: 0.2410\n",
      "Epoch 46/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9893 - loss: 0.0533 - val_accuracy: 0.9306 - val_loss: 0.2403\n",
      "Epoch 47/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9839 - loss: 0.0639 - val_accuracy: 0.9306 - val_loss: 0.2409\n",
      "Epoch 48/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9870 - loss: 0.0530 - val_accuracy: 0.9201 - val_loss: 0.2435\n",
      "Epoch 49/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9900 - loss: 0.0471 - val_accuracy: 0.9201 - val_loss: 0.2432\n",
      "Epoch 50/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9859 - loss: 0.0521 - val_accuracy: 0.9167 - val_loss: 0.2420\n",
      "Epoch 51/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9901 - loss: 0.0458 - val_accuracy: 0.9167 - val_loss: 0.2428\n",
      "Epoch 52/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9890 - loss: 0.0407 - val_accuracy: 0.9236 - val_loss: 0.2443\n",
      "Epoch 53/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9878 - loss: 0.0454 - val_accuracy: 0.9236 - val_loss: 0.2429\n",
      "Epoch 54/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9903 - loss: 0.0414 - val_accuracy: 0.9236 - val_loss: 0.2460\n",
      "Epoch 55/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9868 - loss: 0.0439 - val_accuracy: 0.9201 - val_loss: 0.2469\n",
      "Epoch 56/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0402 - val_accuracy: 0.9271 - val_loss: 0.2462\n",
      "Epoch 57/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9957 - loss: 0.0314 - val_accuracy: 0.9271 - val_loss: 0.2472\n",
      "Epoch 58/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9913 - loss: 0.0358 - val_accuracy: 0.9236 - val_loss: 0.2496\n",
      "Epoch 59/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0348 - val_accuracy: 0.9271 - val_loss: 0.2482\n",
      "Epoch 60/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9972 - loss: 0.0278 - val_accuracy: 0.9271 - val_loss: 0.2517\n",
      "Epoch 61/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9955 - loss: 0.0290 - val_accuracy: 0.9271 - val_loss: 0.2522\n",
      "Epoch 62/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9957 - loss: 0.0295 - val_accuracy: 0.9271 - val_loss: 0.2532\n",
      "Epoch 63/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9944 - loss: 0.0283 - val_accuracy: 0.9271 - val_loss: 0.2544\n",
      "Epoch 64/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9909 - loss: 0.0272 - val_accuracy: 0.9271 - val_loss: 0.2552\n",
      "Epoch 65/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9965 - loss: 0.0238 - val_accuracy: 0.9271 - val_loss: 0.2556\n",
      "Epoch 66/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9954 - loss: 0.0226 - val_accuracy: 0.9271 - val_loss: 0.2578\n",
      "Epoch 67/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9958 - loss: 0.0270 - val_accuracy: 0.9271 - val_loss: 0.2584\n",
      "Epoch 68/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9954 - loss: 0.0264 - val_accuracy: 0.9271 - val_loss: 0.2581\n",
      "Epoch 69/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9964 - loss: 0.0251 - val_accuracy: 0.9271 - val_loss: 0.2615\n",
      "Epoch 70/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9984 - loss: 0.0196 - val_accuracy: 0.9271 - val_loss: 0.2609\n",
      "Epoch 71/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9986 - loss: 0.0209 - val_accuracy: 0.9236 - val_loss: 0.2632\n",
      "Epoch 72/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0202 - val_accuracy: 0.9167 - val_loss: 0.2642\n",
      "Epoch 73/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0181 - val_accuracy: 0.9201 - val_loss: 0.2640\n",
      "Epoch 74/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0173 - val_accuracy: 0.9167 - val_loss: 0.2671\n",
      "Epoch 75/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0169 - val_accuracy: 0.9167 - val_loss: 0.2686\n",
      "Epoch 76/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0157 - val_accuracy: 0.9167 - val_loss: 0.2689\n",
      "Epoch 77/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0134 - val_accuracy: 0.9167 - val_loss: 0.2683\n",
      "Epoch 78/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0166 - val_accuracy: 0.9132 - val_loss: 0.2708\n",
      "Epoch 79/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0150 - val_accuracy: 0.9132 - val_loss: 0.2729\n",
      "Epoch 80/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0161 - val_accuracy: 0.9132 - val_loss: 0.2744\n",
      "Epoch 81/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0144 - val_accuracy: 0.9132 - val_loss: 0.2758\n",
      "Epoch 82/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0147 - val_accuracy: 0.9132 - val_loss: 0.2777\n",
      "Epoch 83/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0122 - val_accuracy: 0.9132 - val_loss: 0.2789\n",
      "Epoch 84/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0107 - val_accuracy: 0.9132 - val_loss: 0.2801\n",
      "Epoch 85/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0118 - val_accuracy: 0.9132 - val_loss: 0.2820\n",
      "Epoch 86/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0098 - val_accuracy: 0.9132 - val_loss: 0.2827\n",
      "Epoch 87/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0121 - val_accuracy: 0.9132 - val_loss: 0.2837\n",
      "Epoch 88/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0100 - val_accuracy: 0.9132 - val_loss: 0.2865\n",
      "Epoch 89/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0099 - val_accuracy: 0.9132 - val_loss: 0.2872\n",
      "Epoch 90/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0077 - val_accuracy: 0.9132 - val_loss: 0.2878\n",
      "Epoch 91/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0083 - val_accuracy: 0.9132 - val_loss: 0.2902\n",
      "Epoch 92/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0100 - val_accuracy: 0.9132 - val_loss: 0.2914\n",
      "Epoch 93/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0090 - val_accuracy: 0.9132 - val_loss: 0.2915\n",
      "Epoch 94/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 0.9132 - val_loss: 0.2953\n",
      "Epoch 95/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0097 - val_accuracy: 0.9132 - val_loss: 0.2954\n",
      "Epoch 96/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0075 - val_accuracy: 0.9132 - val_loss: 0.2964\n",
      "Epoch 97/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0074 - val_accuracy: 0.9132 - val_loss: 0.2974\n",
      "Epoch 98/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0064 - val_accuracy: 0.9132 - val_loss: 0.2975\n",
      "Epoch 99/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0074 - val_accuracy: 0.9132 - val_loss: 0.2991\n",
      "Epoch 100/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.9132 - val_loss: 0.2997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7bf8e9706b70>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "iris = load_digits()\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "procesador = StandardScaler()\n",
    "x = procesador.fit_transform(x)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "modelo = models.Sequential(\n",
    "    [\n",
    "        layers.Input(shape=(64,)),\n",
    "        layers.Dense(10, activation='relu'),\n",
    "        layers.Dense(10, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')  # 10 output units for 10 classes\n",
    "    ]\n",
    ")\n",
    "modelo.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "modelo.fit(x_train, y_train, epochs=100, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddaf41e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.5716 - loss: 0.9812 - val_accuracy: 0.6250 - val_loss: 0.9529\n",
      "Epoch 2/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6016 - loss: 0.9620 - val_accuracy: 0.6250 - val_loss: 0.9410\n",
      "Epoch 3/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5560 - loss: 0.9612 - val_accuracy: 0.6250 - val_loss: 0.9293\n",
      "Epoch 4/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5898 - loss: 0.9281 - val_accuracy: 0.6667 - val_loss: 0.9177\n",
      "Epoch 5/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6042 - loss: 0.9183 - val_accuracy: 0.6667 - val_loss: 0.9056\n",
      "Epoch 6/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6172 - loss: 0.9067 - val_accuracy: 0.6667 - val_loss: 0.8937\n",
      "Epoch 7/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6589 - loss: 0.8808 - val_accuracy: 0.7083 - val_loss: 0.8823\n",
      "Epoch 8/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7305 - loss: 0.8407 - val_accuracy: 0.7500 - val_loss: 0.8709\n",
      "Epoch 9/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7044 - loss: 0.8426 - val_accuracy: 0.7917 - val_loss: 0.8598\n",
      "Epoch 10/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7331 - loss: 0.8275 - val_accuracy: 0.8333 - val_loss: 0.8489\n",
      "Epoch 11/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7135 - loss: 0.8118 - val_accuracy: 0.8750 - val_loss: 0.8381\n",
      "Epoch 12/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7422 - loss: 0.8070 - val_accuracy: 0.8750 - val_loss: 0.8275\n",
      "Epoch 13/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7500 - loss: 0.7703 - val_accuracy: 0.8750 - val_loss: 0.8169\n",
      "Epoch 14/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7995 - loss: 0.7526 - val_accuracy: 0.8333 - val_loss: 0.8063\n",
      "Epoch 15/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7734 - loss: 0.7453 - val_accuracy: 0.7917 - val_loss: 0.7959\n",
      "Epoch 16/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7305 - loss: 0.7727 - val_accuracy: 0.7917 - val_loss: 0.7856\n",
      "Epoch 17/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7852 - loss: 0.7211 - val_accuracy: 0.7917 - val_loss: 0.7754\n",
      "Epoch 18/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7839 - loss: 0.7116 - val_accuracy: 0.7917 - val_loss: 0.7649\n",
      "Epoch 19/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8151 - loss: 0.6872 - val_accuracy: 0.7917 - val_loss: 0.7543\n",
      "Epoch 20/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7917 - loss: 0.6917 - val_accuracy: 0.7917 - val_loss: 0.7440\n",
      "Epoch 21/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8359 - loss: 0.6579 - val_accuracy: 0.7917 - val_loss: 0.7334\n",
      "Epoch 22/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8138 - loss: 0.6633 - val_accuracy: 0.7917 - val_loss: 0.7233\n",
      "Epoch 23/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8008 - loss: 0.6380 - val_accuracy: 0.7917 - val_loss: 0.7135\n",
      "Epoch 24/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7734 - loss: 0.6869 - val_accuracy: 0.7917 - val_loss: 0.7039\n",
      "Epoch 25/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8008 - loss: 0.6423 - val_accuracy: 0.7917 - val_loss: 0.6940\n",
      "Epoch 26/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8177 - loss: 0.6455 - val_accuracy: 0.7917 - val_loss: 0.6847\n",
      "Epoch 27/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8620 - loss: 0.5923 - val_accuracy: 0.7917 - val_loss: 0.6757\n",
      "Epoch 28/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8555 - loss: 0.5968 - val_accuracy: 0.7917 - val_loss: 0.6669\n",
      "Epoch 29/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8633 - loss: 0.5828 - val_accuracy: 0.7917 - val_loss: 0.6583\n",
      "Epoch 30/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8529 - loss: 0.5892 - val_accuracy: 0.7917 - val_loss: 0.6500\n",
      "Epoch 31/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8919 - loss: 0.5636 - val_accuracy: 0.7917 - val_loss: 0.6415\n",
      "Epoch 32/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8372 - loss: 0.5948 - val_accuracy: 0.7917 - val_loss: 0.6335\n",
      "Epoch 33/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8216 - loss: 0.5734 - val_accuracy: 0.7917 - val_loss: 0.6258\n",
      "Epoch 34/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8685 - loss: 0.5057 - val_accuracy: 0.7917 - val_loss: 0.6183\n",
      "Epoch 35/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8633 - loss: 0.5423 - val_accuracy: 0.7917 - val_loss: 0.6109\n",
      "Epoch 36/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8086 - loss: 0.5725 - val_accuracy: 0.7917 - val_loss: 0.6039\n",
      "Epoch 37/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8516 - loss: 0.5355 - val_accuracy: 0.7917 - val_loss: 0.5966\n",
      "Epoch 38/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8164 - loss: 0.5499 - val_accuracy: 0.7917 - val_loss: 0.5897\n",
      "Epoch 39/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8359 - loss: 0.5286 - val_accuracy: 0.7917 - val_loss: 0.5829\n",
      "Epoch 40/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8359 - loss: 0.5092 - val_accuracy: 0.7917 - val_loss: 0.5761\n",
      "Epoch 41/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8125 - loss: 0.5378 - val_accuracy: 0.7917 - val_loss: 0.5697\n",
      "Epoch 42/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8594 - loss: 0.4901 - val_accuracy: 0.7917 - val_loss: 0.5633\n",
      "Epoch 43/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8281 - loss: 0.5254 - val_accuracy: 0.7917 - val_loss: 0.5571\n",
      "Epoch 44/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8359 - loss: 0.5046 - val_accuracy: 0.7917 - val_loss: 0.5511\n",
      "Epoch 45/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8398 - loss: 0.5261 - val_accuracy: 0.7917 - val_loss: 0.5451\n",
      "Epoch 46/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8555 - loss: 0.4564 - val_accuracy: 0.7917 - val_loss: 0.5394\n",
      "Epoch 47/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8398 - loss: 0.4511 - val_accuracy: 0.7917 - val_loss: 0.5338\n",
      "Epoch 48/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8750 - loss: 0.4387 - val_accuracy: 0.7917 - val_loss: 0.5283\n",
      "Epoch 49/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8555 - loss: 0.4337 - val_accuracy: 0.7917 - val_loss: 0.5229\n",
      "Epoch 50/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8594 - loss: 0.4421 - val_accuracy: 0.7917 - val_loss: 0.5179\n",
      "Epoch 51/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8320 - loss: 0.4719 - val_accuracy: 0.7917 - val_loss: 0.5134\n",
      "Epoch 52/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8281 - loss: 0.4815 - val_accuracy: 0.7917 - val_loss: 0.5090\n",
      "Epoch 53/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8320 - loss: 0.4325 - val_accuracy: 0.7917 - val_loss: 0.5046\n",
      "Epoch 54/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8242 - loss: 0.4545 - val_accuracy: 0.7917 - val_loss: 0.5003\n",
      "Epoch 55/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8242 - loss: 0.4592 - val_accuracy: 0.7917 - val_loss: 0.4960\n",
      "Epoch 56/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8438 - loss: 0.4180 - val_accuracy: 0.7917 - val_loss: 0.4919\n",
      "Epoch 57/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8320 - loss: 0.4227 - val_accuracy: 0.7917 - val_loss: 0.4881\n",
      "Epoch 58/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8359 - loss: 0.4369 - val_accuracy: 0.7917 - val_loss: 0.4843\n",
      "Epoch 59/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8164 - loss: 0.4598 - val_accuracy: 0.7917 - val_loss: 0.4806\n",
      "Epoch 60/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8359 - loss: 0.4213 - val_accuracy: 0.7917 - val_loss: 0.4769\n",
      "Epoch 61/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8438 - loss: 0.3963 - val_accuracy: 0.7917 - val_loss: 0.4734\n",
      "Epoch 62/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8828 - loss: 0.3812 - val_accuracy: 0.7917 - val_loss: 0.4696\n",
      "Epoch 63/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8281 - loss: 0.4272 - val_accuracy: 0.7917 - val_loss: 0.4663\n",
      "Epoch 64/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8594 - loss: 0.3971 - val_accuracy: 0.7917 - val_loss: 0.4627\n",
      "Epoch 65/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8789 - loss: 0.3727 - val_accuracy: 0.7917 - val_loss: 0.4593\n",
      "Epoch 66/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8281 - loss: 0.4075 - val_accuracy: 0.7917 - val_loss: 0.4564\n",
      "Epoch 67/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8711 - loss: 0.3698 - val_accuracy: 0.7917 - val_loss: 0.4530\n",
      "Epoch 68/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8464 - loss: 0.3577 - val_accuracy: 0.8333 - val_loss: 0.4499\n",
      "Epoch 69/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8424 - loss: 0.3644 - val_accuracy: 0.8333 - val_loss: 0.4467\n",
      "Epoch 70/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8542 - loss: 0.3651 - val_accuracy: 0.8333 - val_loss: 0.4440\n",
      "Epoch 71/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8021 - loss: 0.3800 - val_accuracy: 0.8333 - val_loss: 0.4413\n",
      "Epoch 72/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8568 - loss: 0.3483 - val_accuracy: 0.8333 - val_loss: 0.4382\n",
      "Epoch 73/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8490 - loss: 0.3452 - val_accuracy: 0.8333 - val_loss: 0.4353\n",
      "Epoch 74/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8333 - loss: 0.3561 - val_accuracy: 0.8333 - val_loss: 0.4324\n",
      "Epoch 75/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8021 - loss: 0.3716 - val_accuracy: 0.8750 - val_loss: 0.4302\n",
      "Epoch 76/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8138 - loss: 0.3497 - val_accuracy: 0.8750 - val_loss: 0.4277\n",
      "Epoch 77/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8620 - loss: 0.3423 - val_accuracy: 0.8750 - val_loss: 0.4252\n",
      "Epoch 78/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8711 - loss: 0.3329 - val_accuracy: 0.8750 - val_loss: 0.4226\n",
      "Epoch 79/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8711 - loss: 0.3185 - val_accuracy: 0.8750 - val_loss: 0.4200\n",
      "Epoch 80/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8359 - loss: 0.3442 - val_accuracy: 0.8750 - val_loss: 0.4174\n",
      "Epoch 81/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8398 - loss: 0.3377 - val_accuracy: 0.8750 - val_loss: 0.4149\n",
      "Epoch 82/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8359 - loss: 0.3484 - val_accuracy: 0.8750 - val_loss: 0.4122\n",
      "Epoch 83/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8854 - loss: 0.3243 - val_accuracy: 0.8750 - val_loss: 0.4089\n",
      "Epoch 84/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8737 - loss: 0.3272 - val_accuracy: 0.8750 - val_loss: 0.4065\n",
      "Epoch 85/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8594 - loss: 0.3236 - val_accuracy: 0.8750 - val_loss: 0.4040\n",
      "Epoch 86/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9036 - loss: 0.3144 - val_accuracy: 0.8750 - val_loss: 0.4012\n",
      "Epoch 87/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8724 - loss: 0.3248 - val_accuracy: 0.8750 - val_loss: 0.3988\n",
      "Epoch 88/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8607 - loss: 0.3378 - val_accuracy: 0.8750 - val_loss: 0.3967\n",
      "Epoch 89/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8659 - loss: 0.3348 - val_accuracy: 0.8750 - val_loss: 0.3946\n",
      "Epoch 90/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9089 - loss: 0.3007 - val_accuracy: 0.8750 - val_loss: 0.3920\n",
      "Epoch 91/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9206 - loss: 0.3126 - val_accuracy: 0.8750 - val_loss: 0.3892\n",
      "Epoch 92/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8854 - loss: 0.3113 - val_accuracy: 0.8750 - val_loss: 0.3869\n",
      "Epoch 93/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8698 - loss: 0.3155 - val_accuracy: 0.9167 - val_loss: 0.3847\n",
      "Epoch 94/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9167 - loss: 0.2809 - val_accuracy: 0.9167 - val_loss: 0.3819\n",
      "Epoch 95/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8893 - loss: 0.3075 - val_accuracy: 0.9167 - val_loss: 0.3799\n",
      "Epoch 96/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8932 - loss: 0.2989 - val_accuracy: 0.9167 - val_loss: 0.3780\n",
      "Epoch 97/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9010 - loss: 0.2683 - val_accuracy: 0.9167 - val_loss: 0.3756\n",
      "Epoch 98/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9180 - loss: 0.3003 - val_accuracy: 0.9167 - val_loss: 0.3734\n",
      "Epoch 99/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9141 - loss: 0.2850 - val_accuracy: 0.9167 - val_loss: 0.3714\n",
      "Epoch 100/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9062 - loss: 0.2886 - val_accuracy: 0.9167 - val_loss: 0.3694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7bf8e46dc890>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "iris = load_iris()\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "procesador = StandardScaler()\n",
    "x = procesador.fit_transform(x)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "modelo = models.Sequential(\n",
    "    [\n",
    "        layers.Input(shape=(4,)),  # Iris dataset has 4 features\n",
    "        layers.Dense(10, activation='relu'),\n",
    "        layers.Dense(10, activation='relu'),\n",
    "        layers.Dense(3, activation='softmax')  # 3 output units for 3 classes in Iris\n",
    "    ]\n",
    ")\n",
    "modelo.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "modelo.fit(x_train, y_train, epochs=100, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d979d5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2164 - loss: 2.2684 - val_accuracy: 0.5556 - val_loss: 2.0229\n",
      "Epoch 2/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6067 - loss: 1.9280 - val_accuracy: 0.6389 - val_loss: 1.5121\n",
      "Epoch 3/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7323 - loss: 1.3659 - val_accuracy: 0.8472 - val_loss: 0.9298\n",
      "Epoch 4/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8570 - loss: 0.7986 - val_accuracy: 0.9097 - val_loss: 0.5912\n",
      "Epoch 5/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9021 - loss: 0.5258 - val_accuracy: 0.8958 - val_loss: 0.4285\n",
      "Epoch 6/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9146 - loss: 0.3905 - val_accuracy: 0.9514 - val_loss: 0.3073\n",
      "Epoch 7/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9330 - loss: 0.3101 - val_accuracy: 0.9514 - val_loss: 0.2674\n",
      "Epoch 8/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9452 - loss: 0.2466 - val_accuracy: 0.9653 - val_loss: 0.2221\n",
      "Epoch 9/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9351 - loss: 0.2477 - val_accuracy: 0.9583 - val_loss: 0.2248\n",
      "Epoch 10/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9523 - loss: 0.1978 - val_accuracy: 0.9583 - val_loss: 0.1822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7bf8eb3afa10>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "digitos = load_digits()\n",
    "x = digitos.images\n",
    "y = digitos.target\n",
    "\n",
    "x = x / 16.0  # Normalizar los valores de píxeles a [0, 1]\n",
    "x = np.expand_dims(x, axis=-1)  # Añadir una dimensión para el canal de color\n",
    "y_cat = to_categorical(y, num_classes=10)  # Convertir a codificación one-hot\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y_cat, test_size=0.2, random_state=42)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(8, 8, 1)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
